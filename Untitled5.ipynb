{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D9rHBNX-yxKM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Dense, Masking\n",
        "from keras.layers import Attention, LayerNormalization, Dropout\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zVVxY3ujzFZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0d5333-4445-4973-9820-8b4cd08b26b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/\")\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "ETwXiUN6zHsq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ffef0660-a7b3-4aca-dd59-d6baa3b10eb6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('SinhalaData.csv')"
      ],
      "metadata": {
        "id": "7ghbNVa-8E1E"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "pc85GG0N8JmG",
        "outputId": "111bae6f-e26f-42d3-f189-a92c44940169"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 english  \\\n",
              "0                 you will receive a package in the mail   \n",
              "1      you will receive a confirmation code after com...   \n",
              "2      you will receive a discount on your next purchase   \n",
              "3      you will receive a phone call from our custome...   \n",
              "4      you will receive a notification when your orde...   \n",
              "...                                                  ...   \n",
              "80679  Deep in the enchanted forest a group of woodla...   \n",
              "80680  On a sunny summer day a group of friends gathe...   \n",
              "80681  In a quaint seaside village a mysterious stran...   \n",
              "80682  Thomas an aspiring writer found inspiration in...   \n",
              "80683  In a land of mythical creatures a young dragon...   \n",
              "\n",
              "                                                 sinhala  \n",
              "0                     ඔයාට තැපෑලෙන් පැකේජ් එකක් හම්බවේවි  \n",
              "1      ලියාපදිංචිය සම්පූර්ණ කලාට පස්සෙ ඔයාට තහවුරු කි...  \n",
              "2          ඊලඟ මිලදී ගැනීම කරන කොට ඔයාට වට්ටමක් හම්බවේවි  \n",
              "3      ඔයාට අපේ පාරිභෝගික සේවා කණ්ඩායමෙන් දුරකථන ඇමතු...  \n",
              "4      ඔයාගේ ඇණවුම සූදානම් උනාට පස්සෙ ඔයාට දැනුම් දීම...  \n",
              "...                                                  ...  \n",
              "80679  වශීකෘත වනාන්තරයේ ගැඹුරින් නුවණැති මහලු බකමූණෙක...  \n",
              "80680  අව්ව සහිත ගිම්හාන දිනයක මිතුරන් පිරිසක් වැලි ම...  \n",
              "80681  විචිත්‍රවත් මුහුදු වෙරළේ ගම්මානයකට අද්භූත ආගන්...  \n",
              "80682  අභිලාෂකාමී ලේඛකයෙකු වන තෝමස් සෑම අස්සක් මුල්ලක...  \n",
              "80683  මිථ්‍යා ජීවීන් සිටින රටක එම්බර් නම් තරුණ මකරෙක...  \n",
              "\n",
              "[80684 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8534d9c9-718f-43ad-b6d7-fb7b3acf05d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>sinhala</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>you will receive a package in the mail</td>\n",
              "      <td>ඔයාට තැපෑලෙන් පැකේජ් එකක් හම්බවේවි</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>you will receive a confirmation code after com...</td>\n",
              "      <td>ලියාපදිංචිය සම්පූර්ණ කලාට පස්සෙ ඔයාට තහවුරු කි...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>you will receive a discount on your next purchase</td>\n",
              "      <td>ඊලඟ මිලදී ගැනීම කරන කොට ඔයාට වට්ටමක් හම්බවේවි</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>you will receive a phone call from our custome...</td>\n",
              "      <td>ඔයාට අපේ පාරිභෝගික සේවා කණ්ඩායමෙන් දුරකථන ඇමතු...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>you will receive a notification when your orde...</td>\n",
              "      <td>ඔයාගේ ඇණවුම සූදානම් උනාට පස්සෙ ඔයාට දැනුම් දීම...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80679</th>\n",
              "      <td>Deep in the enchanted forest a group of woodla...</td>\n",
              "      <td>වශීකෘත වනාන්තරයේ ගැඹුරින් නුවණැති මහලු බකමූණෙක...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80680</th>\n",
              "      <td>On a sunny summer day a group of friends gathe...</td>\n",
              "      <td>අව්ව සහිත ගිම්හාන දිනයක මිතුරන් පිරිසක් වැලි ම...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80681</th>\n",
              "      <td>In a quaint seaside village a mysterious stran...</td>\n",
              "      <td>විචිත්‍රවත් මුහුදු වෙරළේ ගම්මානයකට අද්භූත ආගන්...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80682</th>\n",
              "      <td>Thomas an aspiring writer found inspiration in...</td>\n",
              "      <td>අභිලාෂකාමී ලේඛකයෙකු වන තෝමස් සෑම අස්සක් මුල්ලක...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80683</th>\n",
              "      <td>In a land of mythical creatures a young dragon...</td>\n",
              "      <td>මිථ්‍යා ජීවීන් සිටින රටක එම්බර් නම් තරුණ මකරෙක...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80684 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8534d9c9-718f-43ad-b6d7-fb7b3acf05d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8534d9c9-718f-43ad-b6d7-fb7b3acf05d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8534d9c9-718f-43ad-b6d7-fb7b3acf05d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d97b1724-8d78-4887-87fd-3e1be046d20f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d97b1724-8d78-4887-87fd-3e1be046d20f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d97b1724-8d78-4887-87fd-3e1be046d20f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7c4c9e13-e303-4165-b64f-f78f47a61bdc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7c4c9e13-e303-4165-b64f-f78f47a61bdc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 80684,\n  \"fields\": [\n    {\n      \"column\": \"english\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 67189,\n        \"samples\": [\n          \"where is your phone\",\n          \"nice to hear your voice i live i am fine\",\n          \"it's all about chasing a noble dream\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sinhala\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 69329,\n        \"samples\": [\n          \"\\u0db8\\u0dda \\u0db6\\u0dbd\\u0db1\\u0dca\\u0db1\\u0d9a\\u0ddc\\u0dc4\\u0ddc\\u0db8\\u0daf \\u0dc0\\u0dd0\\u0dbd\\u0daf\\u0d9c\\u0db1\\u0dca\\u0db1\\u0dda \\u0d9a\\u0dd2\\u0dba\\u0dbd\",\n          \"\\u0da2\\u0db1\\u0dcf\\u0db0\\u0dd2\\u0db4\\u0dad\\u0dd2\\u0dad\\u0dd4\\u0db8\\u0dcf \\u0d9c\\u0dcf\\u0dc0\\u0da7\\u0dc0\\u0dad\\u0dca \\u0d91\\u0db1\\u0dca\\u0db1 \\u0db6\\u0dd0\\u0dbb\\u0dd2 \\u0dc0\\u0dd9\\u0dba\\u0dd2\",\n          \"\\u0d85\\u0db4\\u0dd2\\u0da7 \\u0db8\\u0dd9\\u0dba\\u0dcf\\u0dc0 \\u0db1\\u0dda\\u0db8\\u0dbb\\u0dca \\u0da7 \\u0daf\\u0dd9\\u0db1\\u0dca\\u0db1 \\u0db6\\u0dd1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spa_sentences = df[\"sinhala\"] + \"\\t\" + df[\"english\"]\n",
        "\n",
        "# Save the concatenated sentences to a text file\n",
        "with open(\"spa.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    for sentence in spa_sentences:\n",
        "        file.write(str(sentence) + \"\\n\")"
      ],
      "metadata": {
        "id": "w582iaWz8hlc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_file =\"spa.txt\""
      ],
      "metadata": {
        "id": "K1JULi9f-5zw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mNamCma-F6SP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_file =\"spa.txt\"\n",
        "with open(text_file) as f:\n",
        "  lines=f.read().split(\"\\n\")[:-1]"
      ],
      "metadata": {
        "id": "8jN-n1BQAQK5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for line in lines:\n",
        "  print(line)\n",
        "  i=i+1\n",
        "  if(i==20):\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af1PEoZNAXz2",
        "outputId": "17796991-ce93-4296-ceb4-b26e6a057b56"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ඔයාට තැපෑලෙන් පැකේජ් එකක් හම්බවේවි\tyou will receive a package in the mail\n",
            "ලියාපදිංචිය සම්පූර්ණ කලාට පස්සෙ ඔයාට තහවුරු කිරීමේ කේතයක්  හම්බවේවි\tyou will receive a confirmation code after completing the registration\n",
            "ඊලඟ මිලදී ගැනීම කරන කොට ඔයාට වට්ටමක් හම්බවේවි\tyou will receive a discount on your next purchase\n",
            "ඔයාට අපේ පාරිභෝගික සේවා කණ්ඩායමෙන් දුරකථන ඇමතුමක් හම්බවේවි\tyou will receive a phone call from our customer service team\n",
            "ඔයාගේ ඇණවුම සූදානම් උනාට පස්සෙ ඔයාට දැනුම් දීමක් හම්බවේවි\tyou will receive a notification when your order is ready for pickup\n",
            "ඔයාට පැය 24ක් ඇතුලත ඔයාගෙ විමසීමට පිළිතුරක්  හම්බවේවි\tyou will receive a response to your inquiry within 24 hours\n",
            "ඔයාට ඔයාගේ පක්ෂපාතිත්වය වෙනුවෙන් තෑග්ගක් හම්බවේවි\tyou will receive a gift for your loyalty\n",
            "ඔයාට උත්සවයට ආරාධනාවක් හම්බවේවි\tyou will receive an invitation to the event\n",
            "ඔයාට රිටන් කරන භාණ්ඩය වෙනුවෙන් ආපසු මුදල් ගෙවීමක් හම්බවේවි\tyou will receive a refund for the returned item\n",
            "ඔයාට විස්තර එක්ක  ඊමේල් එකක් හම්බවේවි\tyou'll receive an email with the details\n",
            "ඔයාට තැපෑලෙන් පැකේජ් එකක් හම්බවේවි\tyou'll receive a package in the mail\n",
            "ඔයාට රිටන් කරන භාණ්ඩය වෙනුවෙන් ආපසු මුදල් ගෙවීමක් හම්බවේවි\tyou'll receive a refund for the returned item\n",
            "ඔයාට ඔයාගේ පක්ෂපාතිත්වය වෙනුවෙන් තෑග්ගක් හම්බවේවි\tyou'll receive a gift for your loyalty\n",
            "ඔයාගෙ අම්මට කාර් එකක් හම්බවේවි\tyour mother will receive a car\n",
            "ඔයාගෙ සහෝදරයට කාර් එකක් හම්බවේවි\tyour brother will receive a car\n",
            "ඒක මාර ලස්සනයි\tit's pretty cool\n",
            "අපි ඔයාට ආරාධනා කරනවා ඒක කරන්න කියලා\twe're inviting you to do that\n",
            "යන්ත්‍ර පරිවර්තනය දියුණු කරන්න අපිත් එක්ක එකතු වෙන්න\tjoin us in improving machine translation\n",
            "ඔයාගෙ පරිවර්තන NMT මොඩලය පුහුණු කරන්න පාවිච්චි කරාවි\tyour translations will be used to train an nmt model\n",
            "අපි ඔයාට ආරාධනා කරනවා  ZoomNMT පුහුණු කරන්න පරිවර්තන සාම්පල ඉදිරිපත් කරන්න කියලා\twe're inviting you to submit translation samples for the zoomnmt training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(len(lines)-10,len(lines)):\n",
        "  print(lines[x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okVVuwCiAcTd",
        "outputId": "6e470577-0f43-4dcc-ef1d-e7e0213286cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "එක් කලෙක කුඩා ගමක ලිලී නම් තරුණියක් ජීවත් වූ අතර ඇයට ලස්සනම මල් වගා කිරීම සඳහා විශේෂ තෑග්ගක් තිබුණි\tOnce upon a time in a small village there lived a young girl named Lily who had a special gift for growing the most beautiful flowers\n",
            "දුර රටක ශ්‍රීමත් ආතර් නම් නිර්භීත නයිට්වරයා නපුරු මායාකාරයෙකුගෙන් පැහැරගෙන ගිය කුමරියක් බේරා ගැනීමට භයානක ගමනක් ආරම්භ කළේය\tIn a distant land a brave knight named Sir Arthur embarked on a perilous journey to rescue a kidnapped princess from an evil sorcerer\n",
            "කුතුහලය දනවන ගවේෂකයෙකු වන එමිලි ඇමසන් වනාන්තරයේ ගැඹුරින් ගිලිහී ගිය පැරණි නගරයක සැඟවුණු වස්තු සොයා ගැනීමට ත්‍රාසජනක ගමනක් ආරම්භ කළාය\tEmily a curious explorer set out on an adventure to uncover the hidden treasures of an ancient lost city deep in the Amazon rainforest\n",
            "සාමකාමී නගරයක් වන විලෝබෲක්හි ඔලිවර් නම් දඟකාර බළලාට විනෝදජනක සහ අනපේක්ෂිත දුෂ්කරතාවන්ට පත්වීමේ දක්ෂතාවයක් තිබුණි\tIn the peaceful town of Willowbrook a mischievous cat named Oliver had a talent for getting into amusing and unexpected predicaments\n",
            "දක්ෂ පියානෝ වාදකයෙකු වන සාරා Carnegie Hall හි මහා වේදිකාවේ රඟ දැක්වීමට සිහින මැවූ අතර ඇගේ සංගීත ශිල්පය පුහුණු කිරීමට පැය ගණන් ගත කළාය\tSarah a talented pianist dreamt of performing on the grand stage of Carnegie Hall and spent countless hours practicing her musical craft\n",
            "වශීකෘත වනාන්තරයේ ගැඹුරින් නුවණැති මහලු බකමූණෙකු විසින් මෙහෙයවන ලද වනාන්තර ජීවීන් කණ්ඩායමක් තම නිවස විනාශයෙන් බේරා ගැනීමේ ගවේෂණයක යෙදී සිටියහ\tDeep in the enchanted forest a group of woodland creatures led by a wise old owl embarked on a quest to save their home from destruction\n",
            "අව්ව සහිත ගිම්හාන දිනයක මිතුරන් පිරිසක් වැලි මාලිගා ගොඩ නැගීම පිහිනීම සහ සිනහවෙන් විනෝදයෙන් පිරුණු දවසක් සඳහා වෙරළට රැස් වූහ\tOn a sunny summer day a group of friends gathered at the beach for a fun-filled day of sandcastle building swimming and laughter\n",
            "විචිත්‍රවත් මුහුදු වෙරළේ ගම්මානයකට අද්භූත ආගන්තුකයෙකු පැමිණියේ ඔවුන් සමඟ උද්දීපනයක් සහ නගර වැසියන්ගේ ජීවිතයට අනපේක්ෂිත පෙරළියක් ගෙන එයි\tIn a quaint seaside village a mysterious stranger arrived bringing with them an air of excitement and an unexpected twist to the townspeople's lives\n",
            "අභිලාෂකාමී ලේඛකයෙකු වන තෝමස් සෑම අස්සක් මුල්ලක් නෑරම කීමට බලා සිටින කතන්දර ඇති උද්යෝගිමත් නගරයක කාර්යබහුල වීදිවල ආශ්වාදයක් ලබා ගත්තේය\tThomas an aspiring writer found inspiration in the bustling streets of a vibrant city where every corner held a story waiting to be told\n",
            "මිථ්‍යා ජීවීන් සිටින රටක එම්බර් නම් තරුණ මකරෙක් මිත්‍රත්වයේ සහ ධෛර්‍යයේ වටිනා පාඩම් ඉගෙන ගනිමින් ඇගේ ගිනි හුස්ම පාලනය කිරීමට මහත් පරිශ්‍රමයක් දැරීය\tIn a land of mythical creatures a young dragon named Ember struggled to control her fiery breath while learning valuable lessons of friendship and courage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "import re\n",
        "\n",
        "text_pairs = []\n",
        "\n",
        "\n",
        "for line in lines:\n",
        "    if '\\t' in line:\n",
        "        english, sinhala = line.split(\"\\t\")\n",
        "        sinhala = \"[start]\" + sinhala.strip() + \"[end]\"\n",
        "        text_pairs.append((english.strip(), sinhala))\n",
        "for i in range(3):\n",
        "    print(random.choice(text_pairs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3K4lA_TAiKM",
        "outputId": "d9c8f135-d30c-4019-dcf7-d092221e0997"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('එකට පැකිලෙන්නේ නැතිව හරිද', '[start]together without hesitation right[end]')\n",
            "('පොඩ්ඩක් ඉන්න නේෆර් කුමරිය    ඇයි ඔයා මෙහෙ', '[start]wait a minute princess nefer   why are you here[end]')\n",
            "('එයා වාචාලයෙක් මට දැනගන්න ඕන වුනේ ඔයා ගැන තියෙන දේවල්', '[start]he is a rhetorician i wanted to know about you[end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(text_pairs)"
      ],
      "metadata": {
        "id": "OiFINLcyH6SQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_val_samples =int(0.15*len(text_pairs))\n",
        "num_train_samples=len(text_pairs) -2* num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
      ],
      "metadata": {
        "id": "ehIcgOPECGU0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total sentences:\",len(text_pairs))\n",
        "print(\"Training set size:\",len(train_pairs))\n",
        "print(\"Validation set size:\",len(val_pairs))\n",
        "print(\"Testing set size:\",len(test_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSXWkCSiIbFd",
        "outputId": "17ba75ac-2f50-4453-c94b-637e627bb70a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences: 80633\n",
            "Training set size: 56445\n",
            "Validation set size: 12094\n",
            "Testing set size: 12094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_pairs)+len(val_pairs)+len(test_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_InNACfgIypi",
        "outputId": "c48f0bef-f557-4894-805f-3978ad7a9793"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80633"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")"
      ],
      "metadata": {
        "id": "i3SM4fSJI1j8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f\"[{re.escape(strip_chars)}]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5oJtiTLnI4FD",
        "outputId": "d174706d-0159-43f9-e01c-c3b462f9c91a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\\\\\\\\\^_`\\\\{\\\\|\\\\}\\\\~¿]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "def custom_standardization(input_string):\n",
        "  lowercase = tf.strings.lower(input_string)\n",
        "  return tf.strings.regex_replace(\n",
        "    lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "source_vectorization = layers.TextVectorization(\n",
        "  max_tokens=vocab_size,\n",
        "  output_mode=\"int\",\n",
        "  output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "  max_tokens=vocab_size,\n",
        "  output_mode=\"int\",\n",
        "  output_sequence_length=sequence_length + 1,\n",
        "  standardize=custom_standardization,\n",
        ")\n",
        "train_english_texts = [pair[0] for pair in train_pairs]\n",
        "train_spanish_texts = [pair[1] for pair in train_pairs]"
      ],
      "metadata": {
        "id": "e082vYLkI8WY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_vectorization.adapt(train_english_texts)\n",
        "target_vectorization.adapt(train_spanish_texts)"
      ],
      "metadata": {
        "id": "h5kQGr9iJebo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "\n",
        "def format_dataset(eng,spa):\n",
        "  eng=source_vectorization(eng)\n",
        "  spa=target_vectorization(spa)\n",
        "  return({\n",
        "      \"english\":eng,\n",
        "      \"sinhala\":spa[:,:-1],\n",
        "  },spa[:,1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "  eng_texts, spa_texts =zip(*pairs)\n",
        "  eng_texts =list(eng_texts)\n",
        "  spa_texts =list(spa_texts)\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "  return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)\n",
        "\n",
        "for inputs, targets in train_ds.take(1):\n",
        "  print(f\"inputs['english'].shape:{inputs['english'].shape}\")\n",
        "  print(f\"inputs['sinhala'].shape:{inputs['sinhala'].shape}\")\n",
        "  print(f\"targets.shape:{targets.shape}\")\n",
        "\n",
        "  inputs['english'].shape:  (64, 20)\n",
        "  inputs['sinhala'].shape: (64, 20)\n",
        "  targets.shape: (64, 20)\n",
        "print(list(train_ds.as_numpy_iterator())[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1GdUR8fJmYn",
        "outputId": "b2526e7a-87a1-4d75-e9c9-822d1e6e4990"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['english'].shape:(64, 20)\n",
            "inputs['sinhala'].shape:(64, 20)\n",
            "targets.shape:(64, 20)\n",
            "({'english': array([[   32,   137, 11535, ...,     0,     0,     0],\n",
            "       [  337,    11,  1691, ...,     0,     0,     0],\n",
            "       [ 2079,    32,    36, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [    2,    74,     4, ...,     0,     0,     0],\n",
            "       [  562,   462,     0, ...,     0,     0,     0],\n",
            "       [    3,   157,    76, ...,     0,     0,     0]]), 'sinhala': array([[ 890,  182,    0, ...,    0,    0,    0],\n",
            "       [   7, 1412,    2, ...,    0,    0,    0],\n",
            "       [7017,   28, 9357, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   7,   27,   59, ...,    0,    0,    0],\n",
            "       [7157, 1154,    0, ...,    0,    0,    0],\n",
            "       [  52,   34,    2, ...,    0,    0,    0]])}, array([[ 182,    0,    0, ...,    0,    0,    0],\n",
            "       [1412,    2,  163, ...,    0,    0,    0],\n",
            "       [  28, 9357,    0, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  27,   59,    2, ...,    0,    0,    0],\n",
            "       [1154,    0,    0, ...,    0,    0,    0],\n",
            "       [  34,    2,  235, ...,    0,    0,    0]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "ZRe3GQ6tNFWQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = tf.keras.Sequential([\n",
        "            layers.Dense(dense_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "p3-O1MbFMCiz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = tf.keras.Sequential([\n",
        "            layers.Dense(dense_dim, activation=\"relu\"),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask\n",
        "        )\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)\n"
      ],
      "metadata": {
        "id": "nGguNiRsN6RY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "KQzl_V5kOUi6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "\n",
        "# Define the encoder inputs\n",
        "encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
        "\n",
        "# Add positional embedding to the encoder inputs\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "\n",
        "# Encode the inputs using TransformerEncoder\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "\n",
        "# Define the decoder inputs\n",
        "decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"sinhala\")\n",
        "\n",
        "# Add positional embedding to the decoder inputs\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "\n",
        "# Decode the inputs using TransformerDecoder\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
        "\n",
        "# Apply dropout\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Generate decoder outputs\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "# Create the transformer model\n",
        "transformer = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llCLVX_OOkET",
        "outputId": "a445a94c-662b-4edc-c93a-d4bcad58bb63"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " english (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " sinhala (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " positional_embedding (Posi  (None, None, 256)            3845120   ['english[0][0]']             \n",
            " tionalEmbedding)                                                                                 \n",
            "                                                                                                  \n",
            " positional_embedding_1 (Po  (None, None, 256)            3845120   ['sinhala[0][0]']             \n",
            " sitionalEmbedding)                                                                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Trans  (None, None, 256)            3155456   ['positional_embedding[0][0]']\n",
            " formerEncoder)                                                                                   \n",
            "                                                                                                  \n",
            " transformer_decoder (Trans  (None, None, 256)            5259520   ['positional_embedding_1[0][0]\n",
            " formerDecoder)                                                     ',                            \n",
            "                                                                     'transformer_encoder[0][0]'] \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, None, 256)            0         ['transformer_decoder[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, None, 15000)          3855000   ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 19960216 (76.14 MB)\n",
            "Trainable params: 19960216 (76.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(optimizer=\"rmsprop\",\n",
        "                    loss=\"sparse_categorical_crossentropy\",\n",
        "                    metrics=[\"accuracy\"])\n",
        "\n",
        "transformer.fit(train_ds, epochs=30, validation_data=val_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gHl79wMPeZ8",
        "outputId": "471e6249-ced8-43b8-9fde-d544323e67da"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "882/882 [==============================] - 77s 77ms/step - loss: 4.9964 - accuracy: 0.2982 - val_loss: 4.1379 - val_accuracy: 0.3746\n",
            "Epoch 2/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 4.1525 - accuracy: 0.3882 - val_loss: 3.7902 - val_accuracy: 0.4169\n",
            "Epoch 3/30\n",
            "882/882 [==============================] - 65s 73ms/step - loss: 3.7914 - accuracy: 0.4345 - val_loss: 3.5780 - val_accuracy: 0.4465\n",
            "Epoch 4/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 3.5357 - accuracy: 0.4690 - val_loss: 3.4810 - val_accuracy: 0.4631\n",
            "Epoch 5/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 3.3403 - accuracy: 0.4972 - val_loss: 3.4791 - val_accuracy: 0.4726\n",
            "Epoch 6/30\n",
            "882/882 [==============================] - 65s 73ms/step - loss: 3.1834 - accuracy: 0.5204 - val_loss: 3.4568 - val_accuracy: 0.4788\n",
            "Epoch 7/30\n",
            "882/882 [==============================] - 65s 73ms/step - loss: 3.0558 - accuracy: 0.5405 - val_loss: 3.4666 - val_accuracy: 0.4838\n",
            "Epoch 8/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.9536 - accuracy: 0.5575 - val_loss: 3.4953 - val_accuracy: 0.4861\n",
            "Epoch 9/30\n",
            "882/882 [==============================] - 64s 73ms/step - loss: 2.8632 - accuracy: 0.5732 - val_loss: 3.5065 - val_accuracy: 0.4885\n",
            "Epoch 10/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.7876 - accuracy: 0.5868 - val_loss: 3.5911 - val_accuracy: 0.4848\n",
            "Epoch 11/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.7145 - accuracy: 0.5994 - val_loss: 3.5991 - val_accuracy: 0.4909\n",
            "Epoch 12/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.6664 - accuracy: 0.6097 - val_loss: 3.6115 - val_accuracy: 0.4914\n",
            "Epoch 13/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.6089 - accuracy: 0.6208 - val_loss: 3.6275 - val_accuracy: 0.4943\n",
            "Epoch 14/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.5673 - accuracy: 0.6278 - val_loss: 3.6906 - val_accuracy: 0.4938\n",
            "Epoch 15/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.5227 - accuracy: 0.6359 - val_loss: 3.7216 - val_accuracy: 0.4938\n",
            "Epoch 16/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.4872 - accuracy: 0.6436 - val_loss: 3.7606 - val_accuracy: 0.4905\n",
            "Epoch 17/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.4496 - accuracy: 0.6497 - val_loss: 3.7784 - val_accuracy: 0.4917\n",
            "Epoch 18/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.4210 - accuracy: 0.6544 - val_loss: 3.7644 - val_accuracy: 0.4950\n",
            "Epoch 19/30\n",
            "882/882 [==============================] - 60s 68ms/step - loss: 2.3836 - accuracy: 0.6622 - val_loss: 3.7931 - val_accuracy: 0.4926\n",
            "Epoch 20/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.3627 - accuracy: 0.6657 - val_loss: 3.7907 - val_accuracy: 0.4981\n",
            "Epoch 21/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.3352 - accuracy: 0.6710 - val_loss: 3.7841 - val_accuracy: 0.5010\n",
            "Epoch 22/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.3040 - accuracy: 0.6773 - val_loss: 3.8676 - val_accuracy: 0.4972\n",
            "Epoch 23/30\n",
            "882/882 [==============================] - 60s 69ms/step - loss: 2.2784 - accuracy: 0.6812 - val_loss: 3.8452 - val_accuracy: 0.4981\n",
            "Epoch 24/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.2540 - accuracy: 0.6848 - val_loss: 3.9183 - val_accuracy: 0.4904\n",
            "Epoch 25/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.2282 - accuracy: 0.6894 - val_loss: 3.9263 - val_accuracy: 0.4960\n",
            "Epoch 26/30\n",
            "882/882 [==============================] - 60s 68ms/step - loss: 2.2092 - accuracy: 0.6934 - val_loss: 3.9310 - val_accuracy: 0.4997\n",
            "Epoch 27/30\n",
            "882/882 [==============================] - 65s 73ms/step - loss: 2.1909 - accuracy: 0.6967 - val_loss: 3.9822 - val_accuracy: 0.4965\n",
            "Epoch 28/30\n",
            "882/882 [==============================] - 62s 70ms/step - loss: 2.1695 - accuracy: 0.7004 - val_loss: 3.9436 - val_accuracy: 0.4967\n",
            "Epoch 29/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.1496 - accuracy: 0.7040 - val_loss: 3.9836 - val_accuracy: 0.5004\n",
            "Epoch 30/30\n",
            "882/882 [==============================] - 61s 69ms/step - loss: 2.1297 - accuracy: 0.7073 - val_loss: 3.9833 - val_accuracy: 0.4982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cfa69f5e260>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the vocabulary and index lookup for Spanish\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(input_sentence)\n",
        "    print(decode_sequence(input_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oobEWTErhTCp",
        "outputId": "a388b10f-f0a8-4ea2-c33b-94292570250d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "හුස්ම ගන්න\n",
            "[start] breathe[end]                   \n",
            "-\n",
            "ඒ මෙයා  නෑ ඒ ඔයා\n",
            "[start] that he is that[end]                \n",
            "-\n",
            "ප්‍රින්ස් ඉන් නයිජීරියා කියලා එකක්\n",
            "[start] from the [UNK]                 \n",
            "-\n",
            "ඔබේ සිහින සැබෑ වෙනවා\n",
            "[start] your [UNK] fast[end]                 \n",
            "-\n",
            "සේරම වැරදියි\n",
            "[start] all wrong[end]                  \n",
            "-\n",
            "එයා කොහෙද\n",
            "[start] where is he[end]                 \n",
            "-\n",
            "බ්ලැක් පැන්තර් නැතිවෙලා\n",
            "[start] matter the black [UNK]                \n",
            "-\n",
            "සින්ඩින්\n",
            "[start] from the hell[end]                 \n",
            "-\n",
            "ඒ කාලේ මම එයාට වෛර කලා\n",
            "[start] [UNK] they talked to him[end]               \n",
            "-\n",
            "කාලයත් එක්ක වැඩි විස්තර බොඳවෙලා ගියත්\n",
            "[start] [UNK] [UNK] more times a hundred times[end]             \n",
            "-\n",
            "ඊටපස්සේ ඔයාව මරනවා\n",
            "[start] kill you[end]                  \n",
            "-\n",
            "හරිද    කාටවත් හොයාගන්න බෑ ඒක පරිස්සම්\n",
            "[start] no one can find out about it[end]             \n",
            "-\n",
            "මේ ග්‍රීන්ලන්තේ කදවුරයි\n",
            "[start] from the [UNK] city[end]                \n",
            "-\n",
            "මම නූලක් අදින හැමවෙලාවෙම ඒක ලෙහෙනවා නැතිවෙනවා\n",
            "[start] [UNK] for all time i make it to save both times[end]         \n",
            "-\n",
            "වාව්\n",
            "[start] wow[end]                   \n",
            "-\n",
            "අපි හැමදාම වැඩ කරන දේ\n",
            "[start] things we work[end]                 \n",
            "-\n",
            "ඔයාට ඒක මකලා දාන්න වෙනවා\n",
            "[start] put it into the middle it[end]              \n",
            "-\n",
            "මොකක්හරි මගේ මුල් කේත වල වෙනසක් වෙලා\n",
            "[start] from my number of one i are in trouble[end]           \n",
            "-\n",
            "ඔර්ලන්ඩ් ගුවන් හමුදා මුලස්ථානය\n",
            "[start] [UNK] [UNK] the the the building[end]              \n",
            "-\n",
            "ඔයාගෙ සහායකයා කියෙරාටත්\n",
            "[start] from your [UNK]                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the vocabulary and index lookup for Sinhala\n",
        "sin_vocab = target_vectorization.get_vocabulary()\n",
        "sin_index_lookup = dict(zip(range(len(sin_vocab)), sin_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = sin_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "\n",
        "for _ in range(20):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    print(\"-\")\n",
        "    print(\"English: \", input_sentence)\n",
        "    print(\"Sinhala: \", decode_sequence(input_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffe0dzs6hldz",
        "outputId": "33fc290b-830f-4286-ae92-440688173ebd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "English:  හරි ස්තූතියි\n",
            "Sinhala:  [start] thank you[end]                  \n",
            "-\n",
            "English:  ගොඩක් වගකිවයුතු නිළධාරීන් හිරේ යවන්න පුළුවන් අපරාධයක්\n",
            "Sinhala:  [start] [UNK] can be put in our [UNK]             \n",
            "-\n",
            "English:  එපා එපා\n",
            "Sinhala:  [start] do not do not[end]                \n",
            "-\n",
            "English:  මම ඔයාට කිව්වා රගුබීර් දුශ්ටයෙක් නොවෙනකල්\n",
            "Sinhala:  [start] i told you raghubir was [UNK]              \n",
            "-\n",
            "English:  මම දන්නවා ඔයා යන්න කැමතියි පෘතුගාලයට\n",
            "Sinhala:  [start] know you like i dont have to go away[end]           \n",
            "-\n",
            "English:  ලියා ගෙන් ඈත් වෙලා ඉන්නවා\n",
            "Sinhala:  [start] from there is away[end]                \n",
            "-\n",
            "English:  මේ පුංචි සිද්ධිය සහ මම අද සැලසුම් කරලා තියෙන දේ\n",
            "Sinhala:  [start] little i have an [UNK] between this and i said[end]          \n",
            "-\n",
            "English:  144 වන උත්සාහය\n",
            "Sinhala:  [start] attempt[end]                   \n",
            "-\n",
            "English:  ඉදගන්න බැරිවුනඇවිදින්න බැරිවුන\n",
            "Sinhala:  [start] [UNK] the [UNK]                 \n",
            "-\n",
            "English:  ඊට පස්සෙ හිතනවා පවුලෙ අයටයි යාළුවොන්ටයි ඔයාට තේරෙන්නෙ නෑ කියලා\n",
            "Sinhala:  [start] think of the family will not give you [UNK] to the family[end]        \n",
            "-\n",
            "English:  ඔහොම පස්ස උඩ ඉඳගෙන කිසිම දෙයක් විසඳන්න බෑ\n",
            "Sinhala:  [start] from back no one cannot remove people here too[end]           \n",
            "-\n",
            "English:  හැබෑට     ඔව්\n",
            "Sinhala:  [start] young yes[end]                  \n",
            "-\n",
            "English:  මොකක්\n",
            "Sinhala:  [start] what[end]                   \n",
            "-\n",
            "English:  කැමති\n",
            "Sinhala:  [start] like[end]                   \n",
            "-\n",
            "English:  මාර්ෆැටියාඉක්මනටම මේ කොල්ලගේ ලියකියවිලි ලෑස්ති කරන්න\n",
            "Sinhala:  [start] from these [UNK] are ready to hell[end]             \n",
            "-\n",
            "English:  මම උඔගේ අම්මව ඩිවෝස් කරනවා\n",
            "Sinhala:  [start] your mother [UNK]                 \n",
            "-\n",
            "English:  වයිකින්ගේ තාත්තා මුලින්ම පටන් ගන්නකොට\n",
            "Sinhala:  [start] father started first[end]                 \n",
            "-\n",
            "English:  මගේ තාත්තා නැතිවුනා  මට සමාවෙන්න\n",
            "Sinhala:  [start] dad i am sorry to my father[end]             \n",
            "-\n",
            "English:  මේක මතක් කරගන්න\n",
            "Sinhala:  [start] remember this[end]                  \n",
            "-\n",
            "English:  හරි හොඳයි\n",
            "Sinhala:  [start] good[end]                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the vocabulary and index lookup for Sinhala\n",
        "sin_vocab = target_vectorization.get_vocabulary()\n",
        "sin_index_lookup = dict(zip(range(len(sin_vocab)), sin_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = sin_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# Get English input from the user\n",
        "input_sentence = input(\"Enter an English sentence: \")\n",
        "\n",
        "# Translate the input sentence to Sinhala\n",
        "translated_sentence = decode_sequence(input_sentence)\n",
        "\n",
        "# Print the translated sentence\n",
        "print(\"Sinhala translation:\", translated_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Br7yrudhyLK",
        "outputId": "956ab846-c1a8-4fb0-966a-532bc3f1711a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter an English sentence: අපි හැමදාම වැඩ කරන දේ\n",
            "Sinhala translation: [start] things we work[end]                 \n"
          ]
        }
      ]
    }
  ]
}